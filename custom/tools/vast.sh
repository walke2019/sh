#!/bin/bash
# Vast.ai GPUå®¹å™¨ä¸“ç”¨ç®¡ç†å·¥å…·
# ç‰ˆæœ¬: 2.1.0
# é€‚é…: Dockerè™šæ‹Ÿç¯å¢ƒ / Vast.aiå¹³å°

VERSION="2.1.0"

# é¢œè‰²å®šä¹‰
RED='\033[31m'
GREEN='\033[32m'
YELLOW='\033[33m'
BLUE='\033[34m'
CYAN='\033[36m'
MAGENTA='\033[35m'
WHITE='\033[37m'
RESET='\033[0m'

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${CYAN}[INFO]${RESET} $1"
}

log_success() {
    echo -e "${GREEN}[âœ“]${RESET} $1"
}

log_warning() {
    echo -e "${YELLOW}[!]${RESET} $1"
}

log_error() {
    echo -e "${RED}[âœ—]${RESET} $1"
}

# æŒ‰é”®ç»§ç»­
press_enter() {
    echo ""
    read -p "æŒ‰å›è½¦é”®ç»§ç»­..."
}

# æ£€æµ‹ç¯å¢ƒä¿¡æ¯
detect_environment() {
    clear
    echo -e "${CYAN}=== æ­£åœ¨æ£€æµ‹ç¯å¢ƒä¿¡æ¯ ===${RESET}"
    echo ""
    
    # æ£€æµ‹æ˜¯å¦åœ¨Dockerå®¹å™¨ä¸­
    if [ -f /.dockerenv ] || grep -q docker /proc/1/cgroup 2>/dev/null; then
        IN_DOCKER=true
        log_info "æ£€æµ‹åˆ°Dockerå®¹å™¨ç¯å¢ƒ"
    else
        IN_DOCKER=false
        log_warning "éDockerç¯å¢ƒ"
    fi
    
    # æ£€æµ‹CUDAç‰ˆæœ¬
    if command -v nvidia-smi &>/dev/null; then
        CUDA_VERSION=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}')
        DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
        GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
        GPU_COUNT=$(nvidia-smi --list-gpus | wc -l)
        HAS_GPU=true
    else
        CUDA_VERSION="æœªæ£€æµ‹åˆ°"
        DRIVER_VERSION="æœªæ£€æµ‹åˆ°"
        GPU_NAME="æœªæ£€æµ‹åˆ°"
        GPU_COUNT=0
        HAS_GPU=false
    fi
    
    # æ£€æµ‹nvccç‰ˆæœ¬ï¼ˆç¼–è¯‘å·¥å…·ï¼‰
    if command -v nvcc &>/dev/null; then
        NVCC_VERSION=$(nvcc --version | grep "release" | awk '{print $5}' | cut -d',' -f1)
    else
        NVCC_VERSION="æœªå®‰è£…"
    fi
    
    # æ£€æµ‹Pythonç‰ˆæœ¬
    if command -v python3 &>/dev/null; then
        PYTHON_VERSION=$(python3 --version | awk '{print $2}')
    elif command -v python &>/dev/null; then
        PYTHON_VERSION=$(python --version | awk '{print $2}')
    else
        PYTHON_VERSION="æœªå®‰è£…"
    fi
    
    # æ£€æµ‹PyTorch
    PYTORCH_VERSION=$(python3 -c "import torch; print(torch.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    if [ "$PYTORCH_VERSION" != "æœªå®‰è£…" ]; then
        PYTORCH_CUDA=$(python3 -c "import torch; print(torch.version.cuda)" 2>/dev/null || echo "æœªçŸ¥")
        PYTORCH_GPU=$(python3 -c "import torch; print(torch.cuda.is_available())" 2>/dev/null || echo "False")
    else
        PYTORCH_CUDA="N/A"
        PYTORCH_GPU="N/A"
    fi
    
    # æ£€æµ‹TensorFlow
    TF_VERSION=$(python3 -c "import tensorflow as tf; print(tf.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    if [ "$TF_VERSION" != "æœªå®‰è£…" ]; then
        TF_GPU_COUNT=$(python3 -c "import tensorflow as tf; print(len(tf.config.list_physical_devices('GPU')))" 2>/dev/null || echo "0")
    else
        TF_GPU_COUNT="N/A"
    fi
    
    # æ£€æµ‹å…¶ä»–å¸¸ç”¨åº“
    NUMPY_VERSION=$(python3 -c "import numpy; print(numpy.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    PANDAS_VERSION=$(python3 -c "import pandas; print(pandas.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    OPENCV_VERSION=$(python3 -c "import cv2; print(cv2.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    
    # æ£€æµ‹GPUæ¨ç†å·¥å…·
    ONNXRUNTIME_VERSION=$(python3 -c "import onnxruntime; print(onnxruntime.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    TENSORRT_VERSION=$(python3 -c "import tensorrt; print(tensorrt.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    OPENVINO_VERSION=$(python3 -c "import openvino; print(openvino.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    TRITON_VERSION=$(python3 -c "import tritonclient; print('å·²å®‰è£…')" 2>/dev/null || echo "æœªå®‰è£…")
    
    # æ£€æµ‹æ¨¡å‹åŠ é€Ÿåº“
    DEEPSPEED_VERSION=$(python3 -c "import deepspeed; print(deepspeed.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    VLLM_VERSION=$(python3 -c "import vllm; print(vllm.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    TRTLLM_VERSION=$(python3 -c "import tensorrt_llm; print('å·²å®‰è£…')" 2>/dev/null || echo "æœªå®‰è£…")
    XFORMERS_VERSION=$(python3 -c "import xformers; print(xformers.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    BITSANDBYTES_VERSION=$(python3 -c "import bitsandbytes; print(bitsandbytes.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    FLASHATTN_VERSION=$(python3 -c "import flash_attn; print(flash_attn.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    SAGEATTENTION_VERSION=$(python3 -c "import sageattention; print('å·²å®‰è£…')" 2>/dev/null || echo "æœªå®‰è£…")
    
    # æ£€æµ‹LLMæ¨ç†æ¡†æ¶
    LLAMA_CPP_VERSION=$(python3 -c "import llama_cpp; print(llama_cpp.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    CTRANSFORMERS_VERSION=$(python3 -c "import ctransformers; print(ctransformers.__version__)" 2>/dev/null || echo "æœªå®‰è£…")
    
    # æ£€æµ‹Condaç¯å¢ƒ
    if command -v conda &>/dev/null; then
        CONDA_VERSION=$(conda --version | awk '{print $2}')
        CONDA_ENV=$(conda info --envs | grep '*' | awk '{print $1}')
        CONDA_INSTALLED=true
    else
        CONDA_VERSION="æœªå®‰è£…"
        CONDA_ENV="N/A"
        CONDA_INSTALLED=false
    fi
    
    # ä¿å­˜åˆ°å…¨å±€å˜é‡
    export CUDA_VERSION DRIVER_VERSION GPU_NAME GPU_COUNT NVCC_VERSION
    export PYTHON_VERSION PYTORCH_VERSION PYTORCH_CUDA PYTORCH_GPU
    export TF_VERSION TF_GPU_COUNT NUMPY_VERSION PANDAS_VERSION OPENCV_VERSION
    export ONNXRUNTIME_VERSION TENSORRT_VERSION OPENVINO_VERSION TRITON_VERSION
    export DEEPSPEED_VERSION VLLM_VERSION TRTLLM_VERSION XFORMERS_VERSION BITSANDBYTES_VERSION
    export FLASHATTN_VERSION SAGEATTENTION_VERSION
    export LLAMA_CPP_VERSION CTRANSFORMERS_VERSION
    export CONDA_VERSION CONDA_ENV CONDA_INSTALLED
    export IN_DOCKER HAS_GPU
}

# æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
show_environment() {
    clear
    echo -e "${CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${RESET}"
    echo -e "${CYAN}â•‘        Vast.ai ç¯å¢ƒä¿¡æ¯æŠ¥å‘Š               â•‘${RESET}"
    echo -e "${CYAN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== ç³»ç»Ÿç¯å¢ƒ ===${RESET}"
    echo -e "è¿è¡Œç¯å¢ƒ: ${GREEN}$([ "$IN_DOCKER" = true ] && echo "Dockerå®¹å™¨" || echo "ç‰©ç†æœº")${RESET}"
    echo -e "æ“ä½œç³»ç»Ÿ: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
    echo -e "å†…æ ¸ç‰ˆæœ¬: $(uname -r)"
    echo -e "Pythonç‰ˆæœ¬: ${GREEN}$PYTHON_VERSION${RESET}"
    echo -e "Condaç‰ˆæœ¬: ${GREEN}$CONDA_VERSION${RESET}"
    [ "$CONDA_INSTALLED" = true ] && echo -e "å½“å‰ç¯å¢ƒ: ${GREEN}$CONDA_ENV${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== GPUä¿¡æ¯ ===${RESET}"
    echo -e "GPUæ•°é‡: ${GREEN}$GPU_COUNT${RESET}"
    echo -e "GPUå‹å·: ${GREEN}$GPU_NAME${RESET}"
    echo -e "é©±åŠ¨ç‰ˆæœ¬: ${GREEN}$DRIVER_VERSION${RESET}"
    echo -e "CUDAç‰ˆæœ¬: ${GREEN}$CUDA_VERSION${RESET}"
    echo -e "NVCCç‰ˆæœ¬: ${GREEN}$NVCC_VERSION${RESET}"
    
    if [ "$HAS_GPU" = true ]; then
        echo ""
        echo -e "${YELLOW}=== å®æ—¶GPUçŠ¶æ€ ===${RESET}"
        nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,memory.used,memory.total --format=csv,noheader | \
        while IFS=',' read -r idx name temp util mem_used mem_total; do
            echo -e "${CYAN}GPU $idx:${RESET} $name"
            echo -e "  æ¸©åº¦: $temp | ä½¿ç”¨ç‡: $util"
            echo -e "  æ˜¾å­˜: $mem_used / $mem_total"
        done
    fi
    echo ""
    
    echo -e "${YELLOW}=== PyTorch ===${RESET}"
    echo -e "PyTorchç‰ˆæœ¬: ${GREEN}$PYTORCH_VERSION${RESET}"
    echo -e "PyTorch CUDA: ${GREEN}$PYTORCH_CUDA${RESET}"
    echo -e "GPUå¯ç”¨: ${GREEN}$PYTORCH_GPU${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== TensorFlow ===${RESET}"
    echo -e "TensorFlowç‰ˆæœ¬: ${GREEN}$TF_VERSION${RESET}"
    echo -e "å¯ç”¨GPUæ•°: ${GREEN}$TF_GPU_COUNT${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== å¸¸ç”¨åº“ ===${RESET}"
    echo -e "NumPy: ${GREEN}$NUMPY_VERSION${RESET}"
    echo -e "Pandas: ${GREEN}$PANDAS_VERSION${RESET}"
    echo -e "OpenCV: ${GREEN}$OPENCV_VERSION${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== GPUæ¨ç†å·¥å…· ===${RESET}"
    echo -e "ONNX Runtime: ${GREEN}$ONNXRUNTIME_VERSION${RESET}"
    echo -e "TensorRT: ${GREEN}$TENSORRT_VERSION${RESET}"
    echo -e "OpenVINO: ${GREEN}$OPENVINO_VERSION${RESET}"
    echo -e "Triton Client: ${GREEN}$TRITON_VERSION${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== æ¨¡å‹åŠ é€Ÿåº“ ===${RESET}"
    echo -e "DeepSpeed: ${GREEN}$DEEPSPEED_VERSION${RESET}"
    echo -e "vLLM: ${GREEN}$VLLM_VERSION${RESET}"
    echo -e "TensorRT-LLM: ${GREEN}$TRTLLM_VERSION${RESET}"
    echo -e "xFormers: ${GREEN}$XFORMERS_VERSION${RESET}"
    echo -e "Flash-Attention: ${GREEN}$FLASHATTN_VERSION${RESET}"
    echo -e "SageAttention: ${GREEN}$SAGEATTENTION_VERSION${RESET}"
    echo -e "BitsAndBytes: ${GREEN}$BITSANDBYTES_VERSION${RESET}"
    echo ""
    
    echo -e "${YELLOW}=== LLMæ¨ç†æ¡†æ¶ ===${RESET}"
    echo -e "llama.cpp: ${GREEN}$LLAMA_CPP_VERSION${RESET}"
    echo -e "CTransformers: ${GREEN}$CTRANSFORMERS_VERSION${RESET}"
    echo ""
    
    # æ˜¾ç¤ºç£ç›˜å’Œå†…å­˜
    echo -e "${YELLOW}=== ç³»ç»Ÿèµ„æº ===${RESET}"
    echo "ç£ç›˜ä½¿ç”¨:"
    df -h / | tail -1 | awk '{print "  æ€»å®¹é‡: "$2" | å·²ç”¨: "$3" | å¯ç”¨: "$4" | ä½¿ç”¨ç‡: "$5}'
    echo ""
    echo "å†…å­˜ä½¿ç”¨:"
    free -h | grep Mem | awk '{print "  æ€»å†…å­˜: "$2" | å·²ç”¨: "$3" | å¯ç”¨: "$7}'
    echo ""
    
    press_enter
}

# Condaç¯å¢ƒç®¡ç†
conda_manager() {
    while true; do
        clear
        echo -e "${CYAN}=== Conda ç¯å¢ƒç®¡ç† ===${RESET}"
        echo ""
        
        if [ "$CONDA_INSTALLED" = true ]; then
            echo -e "${GREEN}â— Condaå·²å®‰è£…: $CONDA_VERSION${RESET}"
            echo -e "${GREEN}â— å½“å‰ç¯å¢ƒ: $CONDA_ENV${RESET}"
            echo ""
            echo "ç°æœ‰ç¯å¢ƒåˆ—è¡¨:"
            conda env list
        else
            echo -e "${RED}â—‹ Condaæœªå®‰è£…${RESET}"
        fi
        
        echo ""
        echo "------------------------"
        echo "1. å®‰è£…Minicondaåˆ°/homeç›®å½•"
        echo "2. åˆ›å»ºæ–°çš„Pythonç¯å¢ƒ"
        echo "3. æ¿€æ´»æŒ‡å®šç¯å¢ƒ"
        echo "4. åˆ é™¤æŒ‡å®šç¯å¢ƒ"
        echo "5. åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒ"
        echo "6. å¯¼å‡ºå½“å‰ç¯å¢ƒé…ç½®"
        echo "7. ä»é…ç½®æ–‡ä»¶åˆ›å»ºç¯å¢ƒ"
        echo "8. æ›´æ–°Conda"
        echo "9. æ¸…ç†Condaç¼“å­˜"
        echo "0. è¿”å›ä¸»èœå•"
        echo ""
        read -p "è¯·é€‰æ‹©: " choice
        
        case $choice in
            1)
                install_miniconda
                ;;
            2)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                create_conda_env
                ;;
            3)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                conda env list
                echo ""
                read -p "è¯·è¾“å…¥è¦æ¿€æ´»çš„ç¯å¢ƒå: " env_name
                
                echo ""
                log_info "æ¿€æ´»ç¯å¢ƒçš„å‘½ä»¤:"
                echo -e "${YELLOW}conda activate $env_name${RESET}"
                echo ""
                log_warning "æ³¨æ„: éœ€è¦åœ¨æ–°çš„shellä¸­æ‰‹åŠ¨æ‰§è¡Œä¸Šè¿°å‘½ä»¤"
                press_enter
                ;;
            4)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                conda env list
                echo ""
                read -p "è¯·è¾“å…¥è¦åˆ é™¤çš„ç¯å¢ƒå: " env_name
                read -p "ç¡®è®¤åˆ é™¤ç¯å¢ƒ $env_name? (y/n): " confirm
                
                if [[ "$confirm" =~ ^[Yy]$ ]]; then
                    conda env remove -n $env_name
                    log_success "ç¯å¢ƒå·²åˆ é™¤"
                fi
                press_enter
                ;;
            5)
                conda env list
                press_enter
                ;;
            6)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                read -p "è¾“å‡ºæ–‡ä»¶å (é»˜è®¤environment.yml): " filename
                filename=${filename:-environment.yml}
                
                conda env export > $filename
                log_success "ç¯å¢ƒé…ç½®å·²å¯¼å‡ºåˆ° $filename"
                press_enter
                ;;
            7)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                read -p "è¯·è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„: " config_file
                
                if [ ! -f "$config_file" ]; then
                    log_error "æ–‡ä»¶ä¸å­˜åœ¨"
                    press_enter
                    continue
                fi
                
                conda env create -f $config_file
                log_success "ç¯å¢ƒåˆ›å»ºå®Œæˆ"
                press_enter
                ;;
            8)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                log_info "æ›´æ–°Conda..."
                conda update -n base -c defaults conda
                log_success "Condaæ›´æ–°å®Œæˆ"
                press_enter
                ;;
            9)
                if [ "$CONDA_INSTALLED" = false ]; then
                    log_error "è¯·å…ˆå®‰è£…Conda"
                    press_enter
                    continue
                fi
                
                log_info "æ¸…ç†Condaç¼“å­˜..."
                conda clean --all -y
                log_success "ç¼“å­˜æ¸…ç†å®Œæˆ"
                press_enter
                ;;
            0)
                return
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                sleep 1
                ;;
        esac
        
        # é‡æ–°æ£€æµ‹ç¯å¢ƒ
        detect_environment
    done
}

# å®‰è£…Miniconda
install_miniconda() {
    clear
    echo -e "${CYAN}=== å®‰è£… Miniconda ===${RESET}"
    echo ""
    
    if [ "$CONDA_INSTALLED" = true ]; then
        log_warning "Condaå·²å®‰è£…: $CONDA_VERSION"
        read -p "æ˜¯å¦é‡æ–°å®‰è£…? (y/n): " confirm
        if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
            return
        fi
    fi
    
    INSTALL_DIR="/home/miniconda3"
    
    log_info "Minicondaå°†å®‰è£…åˆ°: $INSTALL_DIR"
    echo ""
    
    # æ£€æµ‹ç³»ç»Ÿæ¶æ„
    ARCH=$(uname -m)
    if [ "$ARCH" = "x86_64" ]; then
        MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh"
    elif [ "$ARCH" = "aarch64" ]; then
        MINICONDA_URL="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"
    else
        log_error "ä¸æ”¯æŒçš„æ¶æ„: $ARCH"
        press_enter
        return
    fi
    
    log_info "ä¸‹è½½Minicondaå®‰è£…è„šæœ¬..."
    wget -O /tmp/miniconda.sh $MINICONDA_URL
    
    if [ $? -ne 0 ]; then
        log_error "ä¸‹è½½å¤±è´¥"
        press_enter
        return
    fi
    
    log_info "å®‰è£…Miniconda..."
    bash /tmp/miniconda.sh -b -p $INSTALL_DIR
    
    if [ $? -ne 0 ]; then
        log_error "å®‰è£…å¤±è´¥"
        press_enter
        return
    fi
    
    rm /tmp/miniconda.sh
    
    # é…ç½®ç¯å¢ƒå˜é‡
    log_info "é…ç½®ç¯å¢ƒå˜é‡..."
    
    CONDA_INIT="
# >>> conda initialize >>>
__conda_setup=\"\$('$INSTALL_DIR/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"
if [ \$? -eq 0 ]; then
    eval \"\$__conda_setup\"
else
    if [ -f \"$INSTALL_DIR/etc/profile.d/conda.sh\" ]; then
        . \"$INSTALL_DIR/etc/profile.d/conda.sh\"
    else
        export PATH=\"$INSTALL_DIR/bin:\$PATH\"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<
"
    
    # æ·»åŠ åˆ°bashrc
    if ! grep -q "conda initialize" ~/.bashrc; then
        echo "$CONDA_INIT" >> ~/.bashrc
    fi
    
    # æ·»åŠ åˆ°bash_profile
    if [ -f ~/.bash_profile ]; then
        if ! grep -q "conda initialize" ~/.bash_profile; then
            echo "$CONDA_INIT" >> ~/.bash_profile
        fi
    fi
    
    # ç«‹å³ç”Ÿæ•ˆ
    export PATH="$INSTALL_DIR/bin:$PATH"
    source $INSTALL_DIR/etc/profile.d/conda.sh
    
    # åˆå§‹åŒ–conda
    conda init bash
    
    # é…ç½®conda
    log_info "é…ç½®Conda..."
    conda config --set auto_activate_base false
    
    log_success "Minicondaå®‰è£…å®Œæˆï¼"
    echo ""
    log_info "å®‰è£…è·¯å¾„: $INSTALL_DIR"
    log_info "è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä½¿ç¯å¢ƒç”Ÿæ•ˆ:"
    echo -e "${YELLOW}source ~/.bashrc${RESET}"
    echo ""
    
    press_enter
    
    # é‡æ–°æ£€æµ‹ç¯å¢ƒ
    detect_environment
}

# åˆ›å»ºCondaç¯å¢ƒ
create_conda_env() {
    clear
    echo -e "${CYAN}=== åˆ›å»º Conda ç¯å¢ƒ ===${RESET}"
    echo ""
    
    read -p "è¯·è¾“å…¥æ–°ç¯å¢ƒåç§°: " env_name
    
    if [ -z "$env_name" ]; then
        log_error "ç¯å¢ƒåä¸èƒ½ä¸ºç©º"
        press_enter
        return
    fi
    
    echo ""
    echo "é€‰æ‹©Pythonç‰ˆæœ¬:"
    echo "1. Python 3.12"
    echo "2. Python 3.11"
    echo "3. Python 3.10"
    read -p "è¯·é€‰æ‹© (é»˜è®¤3.11): " py_choice
    
    case $py_choice in
        1) python_version="3.12" ;;
        2) python_version="3.11" ;;
        3) python_version="3.10" ;;
        "")
            python_version="3.11"
            log_info "ä½¿ç”¨é»˜è®¤ç‰ˆæœ¬: Python 3.11"
            ;;
        *)
            log_error "æ— æ•ˆé€‰æ‹©"
            press_enter
            return
            ;;
    esac
    
    echo ""
    log_info "åˆ›å»ºç¯å¢ƒ: $env_name (Python $python_version)"
    
    conda create -n $env_name python=$python_version -y
    
    if [ $? -eq 0 ]; then
        log_success "ç¯å¢ƒåˆ›å»ºæˆåŠŸï¼"
        echo ""
        log_info "æ¿€æ´»ç¯å¢ƒ:"
        echo -e "${YELLOW}conda activate $env_name${RESET}"
        echo ""
        
        read -p "æ˜¯å¦åœ¨æ–°ç¯å¢ƒä¸­å®‰è£…åŸºç¡€åŒ…? (y/n): " install_basics
        
        if [[ "$install_basics" =~ ^[Yy]$ ]]; then
            log_info "å®‰è£…åŸºç¡€åŒ…..."
            conda run -n $env_name pip install numpy pandas matplotlib ipython jupyter
            log_success "åŸºç¡€åŒ…å®‰è£…å®Œæˆ"
        fi
    else
        log_error "ç¯å¢ƒåˆ›å»ºå¤±è´¥"
    fi
    
    press_enter
}

# å¿«é€Ÿåˆ›å»ºå¸¸ç”¨ç¯å¢ƒ
quick_env_menu() {
    clear
    echo -e "${CYAN}=== å¿«é€Ÿåˆ›å»ºå¸¸ç”¨ç¯å¢ƒ ===${RESET}"
    echo ""
    echo "1. PyTorchç¯å¢ƒ (Python 3.10 + PyTorch + CUDA)"
    echo "2. TensorFlowç¯å¢ƒ (Python 3.10 + TensorFlow + CUDA)"
    echo "3. æ•°æ®ç§‘å­¦ç¯å¢ƒ (Python 3.10 + æ•°æ®åˆ†æå…¨å®¶æ¡¶)"
    echo "4. LLMæ¨ç†ç¯å¢ƒ (Python 3.10 + vLLM + Transformers)"
    echo "0. è¿”å›"
    echo ""
    read -p "è¯·é€‰æ‹©: " choice
    
    case $choice in
        1)
            log_info "åˆ›å»ºPyTorchç¯å¢ƒ..."
            conda create -n pytorch python=3.10 -y
            conda run -n pytorch pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
            conda run -n pytorch pip install numpy pandas matplotlib jupyter
            log_success "PyTorchç¯å¢ƒåˆ›å»ºå®Œæˆï¼ä½¿ç”¨: conda activate pytorch"
            ;;
        2)
            log_info "åˆ›å»ºTensorFlowç¯å¢ƒ..."
            conda create -n tensorflow python=3.10 -y
            conda run -n tensorflow pip install tensorflow[and-cuda]
            conda run -n tensorflow pip install numpy pandas matplotlib jupyter
            log_success "TensorFlowç¯å¢ƒåˆ›å»ºå®Œæˆï¼ä½¿ç”¨: conda activate tensorflow"
            ;;
        3)
            log_info "åˆ›å»ºæ•°æ®ç§‘å­¦ç¯å¢ƒ..."
            conda create -n datascience python=3.10 -y
            conda run -n datascience pip install numpy pandas matplotlib seaborn scikit-learn jupyter jupyterlab
            log_success "æ•°æ®ç§‘å­¦ç¯å¢ƒåˆ›å»ºå®Œæˆï¼ä½¿ç”¨: conda activate datascience"
            ;;
        4)
            log_info "åˆ›å»ºLLMæ¨ç†ç¯å¢ƒ..."
            conda create -n llm python=3.10 -y
            conda run -n llm pip install vllm transformers accelerate bitsandbytes
            log_success "LLMæ¨ç†ç¯å¢ƒåˆ›å»ºå®Œæˆï¼ä½¿ç”¨: conda activate llm"
            ;;
        0)
            return
            ;;
    esac
    
    press_enter
}

# æ™ºèƒ½æ¨èå¹¶å®‰è£…PyTorch
smart_install_pytorch() {
    clear
    echo -e "${CYAN}=== æ™ºèƒ½å®‰è£… PyTorch ===${RESET}"
    echo ""
    
    if [ "$HAS_GPU" = false ]; then
        log_error "æœªæ£€æµ‹åˆ°GPUï¼Œæ— æ³•å®‰è£…GPUç‰ˆæœ¬"
        press_enter
        return
    fi
    
    log_info "å½“å‰CUDAç‰ˆæœ¬: $CUDA_VERSION"
    log_info "æ­£åœ¨åˆ†ææœ€ä½³åŒ¹é…..."
    echo ""
    
    # æ ¹æ®CUDAç‰ˆæœ¬æ¨èPyTorch
    CUDA_MAJOR=$(echo $CUDA_VERSION | cut -d'.' -f1)
    CUDA_MINOR=$(echo $CUDA_VERSION | cut -d'.' -f2)
    
    if [ "$CUDA_MAJOR" = "12" ]; then
        if [ "$CUDA_MINOR" -ge "1" ]; then
            RECOMMENDED_TORCH="torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
            TORCH_DESC="PyTorch 2.x (CUDA 12.1+)"
        else
            RECOMMENDED_TORCH="torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
            TORCH_DESC="PyTorch 2.x (CUDA 11.8) [å‘ä¸‹å…¼å®¹]"
        fi
    elif [ "$CUDA_MAJOR" = "11" ]; then
        if [ "$CUDA_MINOR" -ge "8" ]; then
            RECOMMENDED_TORCH="torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
            TORCH_DESC="PyTorch 2.x (CUDA 11.8)"
        else
            RECOMMENDED_TORCH="torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117"
            TORCH_DESC="PyTorch 1.13 (CUDA 11.7)"
        fi
    else
        log_error "ä¸æ”¯æŒçš„CUDAç‰ˆæœ¬: $CUDA_VERSION"
        press_enter
        return
    fi
    
    echo -e "${GREEN}æ¨èå®‰è£…:${RESET} $TORCH_DESC"
    echo -e "${YELLOW}å®‰è£…å‘½ä»¤:${RESET} pip3 install $RECOMMENDED_TORCH"
    echo ""
    
    read -p "æ˜¯å¦å®‰è£…æ¨èç‰ˆæœ¬? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        log_info "æ­£åœ¨å®‰è£…..."
        pip3 install $RECOMMENDED_TORCH
        
        # éªŒè¯å®‰è£…
        echo ""
        log_info "éªŒè¯å®‰è£…..."
        python3 << EOF
import torch
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
EOF
        log_success "PyTorchå®‰è£…å®Œæˆï¼"
    fi
    
    press_enter
}

# æ™ºèƒ½æ¨èå¹¶å®‰è£…TensorFlow
smart_install_tensorflow() {
    clear
    echo -e "${CYAN}=== æ™ºèƒ½å®‰è£… TensorFlow ===${RESET}"
    echo ""
    
    if [ "$HAS_GPU" = false ]; then
        log_error "æœªæ£€æµ‹åˆ°GPUï¼Œæ— æ³•å®‰è£…GPUç‰ˆæœ¬"
        press_enter
        return
    fi
    
    log_info "å½“å‰CUDAç‰ˆæœ¬: $CUDA_VERSION"
    log_info "æ­£åœ¨åˆ†ææœ€ä½³åŒ¹é…..."
    echo ""
    
    # æ ¹æ®CUDAç‰ˆæœ¬æ¨èTensorFlow
    CUDA_MAJOR=$(echo $CUDA_VERSION | cut -d'.' -f1)
    
    if [ "$CUDA_MAJOR" = "12" ] || [ "$CUDA_MAJOR" = "11" ]; then
        RECOMMENDED_TF="tensorflow[and-cuda]"
        TF_DESC="TensorFlow 2.15+ (è‡ªåŠ¨åŒ¹é…CUDA)"
    else
        log_error "ä¸æ”¯æŒçš„CUDAç‰ˆæœ¬: $CUDA_VERSION"
        press_enter
        return
    fi
    
    echo -e "${GREEN}æ¨èå®‰è£…:${RESET} $TF_DESC"
    echo -e "${YELLOW}å®‰è£…å‘½ä»¤:${RESET} pip3 install $RECOMMENDED_TF"
    echo ""
    
    read -p "æ˜¯å¦å®‰è£…æ¨èç‰ˆæœ¬? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        log_info "æ­£åœ¨å®‰è£…..."
        pip3 install $RECOMMENDED_TF
        
        # éªŒè¯å®‰è£…
        echo ""
        log_info "éªŒè¯å®‰è£…..."
        python3 << EOF
import tensorflow as tf
print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
print(f"GPUåˆ—è¡¨: {tf.config.list_physical_devices('GPU')}")
print(f"å†…ç½®CUDA: {tf.test.is_built_with_cuda()}")
EOF
        log_success "TensorFlowå®‰è£…å®Œæˆï¼"
    fi
    
    press_enter
}

# æ‰¹é‡å®‰è£…æ·±åº¦å­¦ä¹ ç¯å¢ƒ
batch_install_dl() {
    clear
    echo -e "${CYAN}=== ä¸€é”®å®‰è£…æ·±åº¦å­¦ä¹ ç¯å¢ƒ ===${RESET}"
    echo ""
    
    log_warning "å°†å®‰è£…ä»¥ä¸‹ç»„ä»¶ï¼š"
    echo "- PyTorch (åŒ¹é…å½“å‰CUDA)"
    echo "- TensorFlow (åŒ¹é…å½“å‰CUDA)"
    echo "- å¸¸ç”¨ç§‘å­¦è®¡ç®—åº“"
    echo "- æ•°æ®å¤„ç†åº“"
    echo "- å¯è§†åŒ–å·¥å…·"
    echo ""
    
    read -p "ç¡®è®¤å®‰è£…? (y/n): " confirm
    
    if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
        return
    fi
    
    # æ›´æ–°pip
    log_info "æ›´æ–°pip..."
    pip3 install --upgrade pip
    
    # å®‰è£…PyTorch
    log_info "å®‰è£…PyTorch..."
    CUDA_MAJOR=$(echo $CUDA_VERSION | cut -d'.' -f1)
    if [ "$CUDA_MAJOR" = "12" ]; then
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    elif [ "$CUDA_MAJOR" = "11" ]; then
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    fi
    
    # å®‰è£…TensorFlow
    log_info "å®‰è£…TensorFlow..."
    pip3 install tensorflow[and-cuda]
    
    # å®‰è£…ç§‘å­¦è®¡ç®—åº“
    log_info "å®‰è£…ç§‘å­¦è®¡ç®—åº“..."
    pip3 install numpy scipy scikit-learn
    
    # å®‰è£…æ•°æ®å¤„ç†
    log_info "å®‰è£…æ•°æ®å¤„ç†åº“..."
    pip3 install pandas matplotlib seaborn pillow opencv-python
    
    # å®‰è£…æ·±åº¦å­¦ä¹ å·¥å…·
    log_info "å®‰è£…æ·±åº¦å­¦ä¹ å·¥å…·..."
    pip3 install transformers datasets accelerate
    
    # å®‰è£…Jupyter
    log_info "å®‰è£…Jupyter..."
    pip3 install jupyterlab ipywidgets
    
    log_success "ç¯å¢ƒå®‰è£…å®Œæˆï¼"
    press_enter
}

# ä¾èµ–åº“ç®¡ç†
library_manager() {
    while true; do
        clear
        echo -e "${CYAN}=== ä¾èµ–åº“ç®¡ç† ===${RESET}"
        echo ""
        echo "1. æ™ºèƒ½å®‰è£…PyTorch (è‡ªåŠ¨åŒ¹é…CUDA)"
        echo "2. æ™ºèƒ½å®‰è£…TensorFlow (è‡ªåŠ¨åŒ¹é…CUDA)"
        echo "3. å®‰è£…JAX"
        echo "4. å®‰è£…å¸¸ç”¨ç§‘å­¦è®¡ç®—åº“"
        echo "5. å®‰è£…å›¾åƒå¤„ç†åº“"
        echo "6. å®‰è£…NLPå·¥å…·åº“"
        echo "7. ä¸€é”®å®‰è£…å®Œæ•´ç¯å¢ƒ"
        echo "------------------------"
        echo "8. GPUæ¨ç†å·¥å…·ç®¡ç†"
        echo "9. æŸ¥çœ‹å·²å®‰è£…åº“"
        echo "10. å¸è½½æŒ‡å®šåº“"
        echo "0. è¿”å›ä¸»èœå•"
        echo ""
        read -p "è¯·é€‰æ‹©: " choice
        
        case $choice in
            1)
                smart_install_pytorch
                ;;
            2)
                smart_install_tensorflow
                ;;
            3)
                log_info "å®‰è£…JAX..."
                CUDA_MAJOR=$(echo $CUDA_VERSION | cut -d'.' -f1)
                if [ "$CUDA_MAJOR" = "12" ]; then
                    pip3 install --upgrade "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
                elif [ "$CUDA_MAJOR" = "11" ]; then
                    pip3 install --upgrade "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
                fi
                log_success "JAXå®‰è£…å®Œæˆ"
                press_enter
                ;;
            4)
                log_info "å®‰è£…ç§‘å­¦è®¡ç®—åº“..."
                pip3 install numpy scipy scikit-learn pandas matplotlib seaborn
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            5)
                log_info "å®‰è£…å›¾åƒå¤„ç†åº“..."
                pip3 install pillow opencv-python opencv-contrib-python albumentations
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            6)
                log_info "å®‰è£…NLPå·¥å…·åº“..."
                pip3 install transformers datasets tokenizers sentencepiece
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            7)
                batch_install_dl
                ;;
            8)
                inference_tools_menu
                ;;
            9)
                clear
                echo -e "${CYAN}=== å·²å®‰è£…çš„åº“ ===${RESET}"
                pip3 list | grep -E "torch|tensorflow|numpy|pandas|jax|transformers|onnx|tensorrt|vllm|deepspeed"
                press_enter
                ;;
            10)
                read -p "è¯·è¾“å…¥è¦å¸è½½çš„åº“å: " lib_name
                pip3 uninstall -y $lib_name
                log_success "å·²å¸è½½ $lib_name"
                press_enter
                ;;
            0)
                return
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                sleep 1
                ;;
        esac
    done
}

# GPUç›‘æ§
gpu_monitor() {
    clear
    echo -e "${CYAN}=== GPU å®æ—¶ç›‘æ§ ===${RESET}"
    echo "æŒ‰ Ctrl+C é€€å‡ºç›‘æ§"
    echo ""
    sleep 2
    
    if [ "$HAS_GPU" = true ]; then
        watch -n 1 nvidia-smi
    else
        log_error "æœªæ£€æµ‹åˆ°GPU"
        press_enter
    fi
}

# GPUæ€§èƒ½æµ‹è¯•
gpu_benchmark() {
    clear
    echo -e "${CYAN}=== GPU æ€§èƒ½æµ‹è¯• ===${RESET}"
    echo ""
    
    if [ "$PYTORCH_VERSION" = "æœªå®‰è£…" ]; then
        log_error "è¯·å…ˆå®‰è£…PyTorch"
        press_enter
        return
    fi
    
    log_info "åˆ›å»ºæµ‹è¯•è„šæœ¬..."
    cat > /tmp/gpu_benchmark.py << 'EOF'
import torch
import time
import sys

print("="*50)
print("GPUæ€§èƒ½æµ‹è¯•")
print("="*50)
print(f"\nPyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if not torch.cuda.is_available():
    print("é”™è¯¯: CUDAä¸å¯ç”¨!")
    sys.exit(1)

print(f"\nGPUæ•°é‡: {torch.cuda.device_count()}")
for i in range(torch.cuda.device_count()):
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    props = torch.cuda.get_device_properties(i)
    print(f"  æ˜¾å­˜: {props.total_memory / 1024**3:.2f} GB")
    print(f"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")

# æµ‹è¯•ä¸åŒçŸ©é˜µå¤§å°
sizes = [1000, 5000, 10000]
device = torch.device("cuda:0")

print("\n" + "="*50)
print("çŸ©é˜µä¹˜æ³•æ€§èƒ½æµ‹è¯•")
print("="*50)

for size in sizes:
    print(f"\næµ‹è¯•çŸ©é˜µå¤§å°: {size}x{size}")
    
    a = torch.randn(size, size, device=device, dtype=torch.float32)
    b = torch.randn(size, size, device=device, dtype=torch.float32)
    
    # é¢„çƒ­
    for _ in range(3):
        _ = torch.matmul(a, b)
    torch.cuda.synchronize()
    
    # æ­£å¼æµ‹è¯•
    times = []
    for _ in range(10):
        start = time.time()
        c = torch.matmul(a, b)
        torch.cuda.synchronize()
        times.append(time.time() - start)
    
    avg_time = sum(times) / len(times)
    flops = 2 * size**3 / avg_time / 1e9
    
    print(f"  å¹³å‡æ—¶é—´: {avg_time*1000:.2f} ms")
    print(f"  æ€§èƒ½: {flops:.2f} GFLOPS")
    
    # æ˜¾å­˜ä½¿ç”¨
    memory_allocated = torch.cuda.memory_allocated(device) / 1024**2
    memory_reserved = torch.cuda.memory_reserved(device) / 1024**2
    print(f"  æ˜¾å­˜ä½¿ç”¨: {memory_allocated:.2f} MB (å·²åˆ†é…) / {memory_reserved:.2f} MB (å·²ä¿ç•™)")

print("\næµ‹è¯•å®Œæˆ!")
EOF

    python3 /tmp/gpu_benchmark.py
    press_enter
}

# Jupyterç®¡ç†
jupyter_manager() {
    while true; do
        clear
        echo -e "${CYAN}=== Jupyter ç®¡ç† ===${RESET}"
        echo ""
        echo "1. å®‰è£…JupyterLab"
        echo "2. å¯åŠ¨Jupyter (åå°)"
        echo "3. æŸ¥çœ‹JupyterçŠ¶æ€"
        echo "4. åœæ­¢Jupyter"
        echo "5. è®¾ç½®Jupyterå¯†ç "
        echo "0. è¿”å›ä¸»èœå•"
        echo ""
        read -p "è¯·é€‰æ‹©: " choice
        
        case $choice in
            1)
                log_info "å®‰è£…JupyterLabåŠæ‰©å±•..."
                pip3 install jupyterlab ipywidgets jupyter-resource-usage
                jupyter labextension install @jupyter-widgets/jupyterlab-manager
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            2)
                read -p "ç«¯å£å· (é»˜è®¤8888): " port
                port=${port:-8888}
                
                log_info "å¯åŠ¨Jupyter on port $port..."
                nohup jupyter lab --ip=0.0.0.0 --port=$port --allow-root --no-browser > /tmp/jupyter.log 2>&1 &
                sleep 3
                
                log_success "Jupyterå·²å¯åŠ¨"
                echo ""
                echo "æŸ¥çœ‹Token:"
                jupyter lab list
                press_enter
                ;;
            3)
                jupyter lab list
                press_enter
                ;;
            4)
                pkill -f jupyter
                log_success "Jupyterå·²åœæ­¢"
                press_enter
                ;;
            5)
                jupyter lab password
                press_enter
                ;;
            0)
                return
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                sleep 1
                ;;
        esac
    done
}

# å¿«é€Ÿå¯åŠ¨å¸¸ç”¨å®¹å™¨
quick_start_containers() {
    clear
    echo -e "${CYAN}=== å¿«é€Ÿå¯åŠ¨é¡¹ç›®æ¨¡æ¿ ===${RESET}"
    echo ""
    echo "1. å¯åŠ¨PyTorchè®­ç»ƒç¯å¢ƒ"
    echo "2. å¯åŠ¨TensorFlowè®­ç»ƒç¯å¢ƒ"
    echo "3. å¯åŠ¨Jupyter Notebook"
    echo "4. å¯åŠ¨Stable Diffusion WebUI"
    echo "5. å¯åŠ¨ComfyUI"
    echo "0. è¿”å›"
    echo ""
    read -p "è¯·é€‰æ‹©: " choice
    
    case $choice in
        1)
            log_info "åˆ›å»ºPyTorchè®­ç»ƒç›®å½•..."
            mkdir -p ~/workspace/pytorch-project
            cd ~/workspace/pytorch-project
            
            cat > train.py << 'EOF'
import torch
import torch.nn as nn

print("PyTorchç¯å¢ƒå°±ç»ª!")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
EOF
            
            log_success "é¡¹ç›®å·²åˆ›å»ºåœ¨ ~/workspace/pytorch-project"
            ;;
        2)
            log_info "åˆ›å»ºTensorFlowè®­ç»ƒç›®å½•..."
            mkdir -p ~/workspace/tensorflow-project
            cd ~/workspace/tensorflow-project
            
            cat > train.py << 'EOF'
import tensorflow as tf

print("TensorFlowç¯å¢ƒå°±ç»ª!")
print(f"GPUåˆ—è¡¨: {tf.config.list_physical_devices('GPU')}")
EOF
            
            log_success "é¡¹ç›®å·²åˆ›å»ºåœ¨ ~/workspace/tensorflow-project"
            ;;
        3)
            jupyter_manager
            return
            ;;
        4)
            log_info "å…‹éš†Stable Diffusion WebUI..."
            cd ~
            if [ ! -d "stable-diffusion-webui" ]; then
                git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
            fi
            cd stable-diffusion-webui
            log_info "å¯åŠ¨WebUI..."
            bash webui.sh --listen --port 7860
            ;;
        5)
            log_info "å…‹éš†ComfyUI..."
            cd ~
            if [ ! -d "ComfyUI" ]; then
                git clone https://github.com/comfyanonymous/ComfyUI.git
            fi
            cd ComfyUI
            pip3 install -r requirements.txt
            log_info "å¯åŠ¨ComfyUI..."
            python3 main.py --listen 0.0.0.0 --port 8188
            ;;
        0)
            return
            ;;
    esac
    
    press_enter
}

# ä¸»èœå•
main_menu() {
    while true; do
        clear
        echo -e "${CYAN}"
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘   Vast.ai GPUå®¹å™¨ç®¡ç†å·¥å…· v${VERSION}        â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo -e "${RESET}"
        echo ""
        
        # å¿«é€ŸçŠ¶æ€æ˜¾ç¤º
        if [ "$HAS_GPU" = true ]; then
            echo -e "${GREEN}â— GPUçŠ¶æ€:${RESET} $GPU_COUNT x $GPU_NAME"
            echo -e "${GREEN}â— CUDA:${RESET} $CUDA_VERSION | ${GREEN}PyTorch:${RESET} $PYTORCH_VERSION | ${GREEN}TensorFlow:${RESET} $TF_VERSION"
        else
            echo -e "${RED}â—‹ æœªæ£€æµ‹åˆ°GPU${RESET}"
        fi
        echo ""
        
        echo -e "${YELLOW}ç¯å¢ƒç®¡ç†${RESET}"
        echo "1. ğŸ–¥ï¸  ä¸€é”®æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯"
        echo "2. ğŸ“¦ Condaç¯å¢ƒç®¡ç†"
        echo "3. ğŸ”§ æ™ºèƒ½ä¾èµ–åº“ç®¡ç†"
        echo "4. âš¡ ä¸€é”®å®‰è£…å®Œæ•´ç¯å¢ƒ"
        echo "5. ğŸš€ å¿«é€Ÿåˆ›å»ºå¸¸ç”¨ç¯å¢ƒ"
        echo "6. ğŸ› ï¸  GPUæ¨ç†å·¥å…·ç®¡ç†"
        echo ""
        echo -e "${YELLOW}GPUç›‘æ§${RESET}"
        echo "7. ğŸ“Š GPUå®æ—¶ç›‘æ§"
        echo "8. ğŸ¯ GPUæ€§èƒ½æµ‹è¯•"
        echo "9. âœ… æ¨ç†å·¥å…·æµ‹è¯•"
        echo ""
        echo -e "${YELLOW}å¼€å‘å·¥å…·${RESET}"
        echo "10. ğŸ““ Jupyterç®¡ç†"
        echo "11. ğŸ¨ å¿«é€Ÿå¯åŠ¨é¡¹ç›®"
        echo ""
        echo -e "${YELLOW}ç³»ç»Ÿå·¥å…·${RESET}"
        echo "12. ğŸ”„ åˆ·æ–°ç¯å¢ƒæ£€æµ‹"
        echo "13. ğŸ’» ç³»ç»Ÿä¿¡æ¯"
        echo ""
        echo "0. é€€å‡º"
        echo ""
        read -p "è¯·é€‰æ‹©æ“ä½œ: " choice
        
        case $choice in
            1) show_environment ;;
            2) conda_manager ;;
            3) library_manager ;;
            4) batch_install_dl ;;
            5) quick_env_menu ;;
            6) inference_tools_menu ;;
            7) gpu_monitor ;;
            8) gpu_benchmark ;;
            9) test_inference_tools ;;
            10) jupyter_manager ;;
            11) quick_start_containers ;;
            12) 
                log_info "æ­£åœ¨åˆ·æ–°ç¯å¢ƒä¿¡æ¯..."
                detect_environment
                log_success "ç¯å¢ƒä¿¡æ¯å·²åˆ·æ–°"
                sleep 1
                ;;
            13)
                clear
                echo -e "${CYAN}=== ç³»ç»Ÿè¯¦ç»†ä¿¡æ¯ ===${RESET}"
                echo ""
                echo -e "${YELLOW}ç³»ç»Ÿä¿¡æ¯:${RESET}"
                uname -a
                echo ""
                echo -e "${YELLOW}ç£ç›˜ä½¿ç”¨:${RESET}"
                df -h
                echo ""
                echo -e "${YELLOW}å†…å­˜ä½¿ç”¨:${RESET}"
                free -h
                echo ""
                echo -e "${YELLOW}ç½‘ç»œä¿¡æ¯:${RESET}"
                ip addr show | grep -E "inet |inet6 " | head -5
                press_enter
                ;;
            0)
                log_info "æ„Ÿè°¢ä½¿ç”¨ï¼"
                exit 0
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                sleep 1
                ;;
        esac
    done
}

# GPUæ¨ç†å·¥å…·ç®¡ç†èœå•
inference_tools_menu() {
    while true; do
        clear
        echo -e "${CYAN}=== GPUæ¨ç†å·¥å…·ç®¡ç† ===${RESET}"
        echo ""
        
        echo -e "${YELLOW}å½“å‰å·²å®‰è£…:${RESET}"
        echo "ONNX Runtime: ${GREEN}$ONNXRUNTIME_VERSION${RESET}"
        echo "TensorRT: ${GREEN}$TENSORRT_VERSION${RESET}"
        echo "OpenVINO: ${GREEN}$OPENVINO_VERSION${RESET}"
        echo "vLLM: ${GREEN}$VLLM_VERSION${RESET}"
        echo "DeepSpeed: ${GREEN}$DEEPSPEED_VERSION${RESET}"
        echo "xFormers: ${GREEN}$XFORMERS_VERSION${RESET}"
        echo "Flash-Attention: ${GREEN}$FLASHATTN_VERSION${RESET}"
        echo ""
        
        echo "------------------------"
        echo "1. å®‰è£… ONNX Runtime GPU"
        echo "2. å®‰è£… TensorRT"
        echo "3. å®‰è£… OpenVINO"
        echo "4. å®‰è£… vLLM (LLMé«˜é€Ÿæ¨ç†)"
        echo "5. å®‰è£… DeepSpeed (åˆ†å¸ƒå¼è®­ç»ƒ)"
        echo "6. å®‰è£… TensorRT-LLM"
        echo "7. å®‰è£… xFormers (æ³¨æ„åŠ›åŠ é€Ÿ)"
        echo "8. å®‰è£… Flash-Attention"
        echo "9. å®‰è£… SageAttention"
        echo "10. å®‰è£… BitsAndBytes (é‡åŒ–)"
        echo "11. å®‰è£… llama.cpp Pythonç»‘å®š"
        echo "12. å®‰è£… CTransformers"
        echo "13. å®‰è£… Tritonæ¨ç†æœåŠ¡å™¨å®¢æˆ·ç«¯"
        echo "------------------------"
        echo "14. ä¸€é”®å®‰è£…æ¨ç†å·¥å…·å¥—ä»¶"
        echo "15. æµ‹è¯•æ‰€æœ‰æ¨ç†å·¥å…·"
        echo "0. è¿”å›ä¸»èœå•"
        echo ""
        read -p "è¯·é€‰æ‹©: " choice
        
        case $choice in
            1)
                log_info "å®‰è£… ONNX Runtime GPU..."
                pip3 install onnxruntime-gpu
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            2)
                log_info "å®‰è£… TensorRT..."
                log_warning "TensorRTéœ€è¦ä»NVIDIAå®˜ç½‘ä¸‹è½½å¯¹åº”ç‰ˆæœ¬"
                echo "ä¸‹è½½åœ°å€: https://developer.nvidia.com/tensorrt"
                press_enter
                ;;
            3)
                log_info "å®‰è£… OpenVINO..."
                pip3 install openvino openvino-dev
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            4)
                log_info "å®‰è£… vLLM..."
                pip3 install vllm
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            5)
                log_info "å®‰è£… DeepSpeed..."
                pip3 install deepspeed
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            6)
                log_info "å®‰è£… TensorRT-LLM..."
                log_warning "TensorRT-LLMéœ€è¦ç‰¹å®šç¯å¢ƒï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£"
                echo "GitHub: https://github.com/NVIDIA/TensorRT-LLM"
                press_enter
                ;;
            7)
                log_info "å®‰è£… xFormers..."
                pip3 install xformers
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            8)
                log_info "å®‰è£… Flash-Attention..."
                pip3 install flash-attn --no-build-isolation
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            9)
                log_info "å®‰è£… SageAttention..."
                pip3 install sageattention
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            10)
                log_info "å®‰è£… BitsAndBytes..."
                pip3 install bitsandbytes
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            11)
                log_info "å®‰è£… llama-cpp-python (CUDAæ”¯æŒ)..."
                CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip3 install llama-cpp-python
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            12)
                log_info "å®‰è£… CTransformers..."
                pip3 install ctransformers
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            13)
                log_info "å®‰è£… Tritonå®¢æˆ·ç«¯..."
                pip3 install tritonclient[all]
                log_success "å®‰è£…å®Œæˆ"
                press_enter
                ;;
            14)
                log_info "ä¸€é”®å®‰è£…æ¨ç†å·¥å…·å¥—ä»¶..."
                pip3 install onnxruntime-gpu vllm deepspeed xformers bitsandbytes
                log_success "å¥—ä»¶å®‰è£…å®Œæˆ"
                press_enter
                ;;
            15)
                test_inference_tools
                ;;
            0)
                return
                ;;
            *)
                log_error "æ— æ•ˆé€‰æ‹©"
                sleep 1
                ;;
        esac
        
        # é‡æ–°æ£€æµ‹ç¯å¢ƒ
        detect_environment
    done
}

# æµ‹è¯•æ¨ç†å·¥å…·
test_inference_tools() {
    clear
    echo -e "${CYAN}=== æµ‹è¯•æ¨ç†å·¥å…· ===${RESET}"
    echo ""
    
    log_info "æµ‹è¯• ONNX Runtime..."
    python3 << 'EOF'
try:
    import onnxruntime as ort
    print(f"âœ“ ONNX Runtime {ort.__version__}")
    print(f"  Providers: {ort.get_available_providers()}")
except Exception as e:
    print(f"âœ— ONNX Runtime: {e}")
print()
EOF

    log_info "æµ‹è¯• TensorRT..."
    python3 << 'EOF'
try:
    import tensorrt as trt
    print(f"âœ“ TensorRT {trt.__version__}")
except Exception as e:
    print(f"âœ— TensorRT: {e}")
print()
EOF

    log_info "æµ‹è¯• OpenVINO..."
    python3 << 'EOF'
try:
    import openvino as ov
    print(f"âœ“ OpenVINO {ov.__version__}")
except Exception as e:
    print(f"âœ— OpenVINO: {e}")
print()
EOF

    log_info "æµ‹è¯• vLLM..."
    python3 << 'EOF'
try:
    import vllm
    print(f"âœ“ vLLM {vllm.__version__}")
except Exception as e:
    print(f"âœ— vLLM: {e}")
print()
EOF

    log_info "æµ‹è¯• DeepSpeed..."
    python3 << 'EOF'
try:
    import deepspeed
    print(f"âœ“ DeepSpeed {deepspeed.__version__}")
except Exception as e:
    print(f"âœ— DeepSpeed: {e}")
print()
EOF

    log_info "æµ‹è¯• xFormers..."
    python3 << 'EOF'
try:
    import xformers
    print(f"âœ“ xFormers {xformers.__version__}")
except Exception as e:
    print(f"âœ— xFormers: {e}")
print()
EOF

    log_info "æµ‹è¯• Flash-Attention..."
    python3 << 'EOF'
try:
    import flash_attn
    print(f"âœ“ Flash-Attention {flash_attn.__version__}")
except Exception as e:
    print(f"âœ— Flash-Attention: {e}")
print()
EOF

    log_info "æµ‹è¯• BitsAndBytes..."
    python3 << 'EOF'
try:
    import bitsandbytes as bnb
    print(f"âœ“ BitsAndBytes {bnb.__version__}")
except Exception as e:
    print(f"âœ— BitsAndBytes: {e}")
print()
EOF

    log_info "æµ‹è¯• llama.cpp..."
    python3 << 'EOF'
try:
    import llama_cpp
    print(f"âœ“ llama-cpp-python {llama_cpp.__version__}")
except Exception as e:
    print(f"âœ— llama-cpp-python: {e}")
print()
EOF

    log_info "æµ‹è¯• CTransformers..."
    python3 << 'EOF'
try:
    import ctransformers
    print(f"âœ“ CTransformers {ctransformers.__version__}")
except Exception as e:
    print(f"âœ— CTransformers: {e}")
print()
EOF

    press_enter
}

# åˆå§‹åŒ–
clear
echo -e "${CYAN}æ­£åœ¨åˆå§‹åŒ–...${RESET}"
detect_environment
sleep 1

# è¿è¡Œä¸»èœå•
main_menu